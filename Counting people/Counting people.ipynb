{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import time\n",
    "import glob\n",
    "from progressbar import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "widgets = [Bar('>'), ' ', ETA(), ' ', ReverseBar('<')]\n",
    "pbar = ProgressBar(widgets=widgets, maxval=10000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class People_Counter:\n",
    "\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "        self.detection_graph = tf.Graph()\n",
    "        with self.detection_graph.as_default():\n",
    "            od_graph_def = tf.compat.v1.GraphDef()\n",
    "            with tf.compat.v2.io.gfile.GFile(self.path, 'rb') as fid:\n",
    "                serialized_graph = fid.read()\n",
    "                od_graph_def.ParseFromString(serialized_graph)\n",
    "                tf.import_graph_def(od_graph_def, name='')\n",
    "\n",
    "        self.default_graph = self.detection_graph.as_default()\n",
    "        self.sess = tf.compat.v1.Session(graph=self.detection_graph)\n",
    "\n",
    "        self.image_tensor = self.detection_graph.get_tensor_by_name('image_tensor:0') # Defining tensors for the graph\n",
    "        self.detection_boxes = self.detection_graph.get_tensor_by_name('detection_boxes:0') # Each box denotes part of image with a person detected \n",
    "        self.detection_scores = self.detection_graph.get_tensor_by_name('detection_scores:0') # Score represents the confidence for the detected person\n",
    "        self.detection_classes = self.detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "        self.num_detections = self.detection_graph.get_tensor_by_name('num_detections:0')\n",
    "\n",
    "    def detect(self, image):\n",
    "        image_np_expanded = np.expand_dims(image, axis=0)\n",
    "        (boxes, scores, classes, num) = self.sess.run(\n",
    "            [self.detection_boxes, self.detection_scores, self.detection_classes, self.num_detections],\n",
    "            feed_dict={self.image_tensor: image_np_expanded}) # Using the model for detection\n",
    "\n",
    "        im_height, im_width,_ = image.shape\n",
    "        boxes_list = [None for i in range(boxes.shape[1])]\n",
    "        for i in range(boxes.shape[1]):\n",
    "            boxes_list[i] = (int(boxes[0,i,0] * im_height),\n",
    "                        int(boxes[0,i,1]*im_width),\n",
    "                        int(boxes[0,i,2] * im_height),\n",
    "                        int(boxes[0,i,3]*im_width))\n",
    "\n",
    "        return boxes_list, scores[0].tolist(), [int(x) for x in classes[0].tolist()], int(num[0])\n",
    "\n",
    "    def close(self):\n",
    "        self.sess.close()\n",
    "        self.default_graph.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "|>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>| Time: 0:01:29 |<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<|\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t\t\tSuccessfully saved all results!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    model_path = './data/utils/my_model.pb'\n",
    "    peop_counter = People_Counter(path=model_path)\n",
    "    threshold = 0.4\n",
    "    no=1\n",
    "    for n in pbar(glob.glob(\"./data/images/test/*.jpg\")):\n",
    "        count=0\n",
    "        img = cv2.imread(n)\n",
    "        img = cv2.resize(img, (640, 480))\n",
    "\n",
    "        boxes, scores, classes, num = peop_counter.detect(img)\n",
    "\n",
    "        for i in range(len(boxes)):\n",
    "            if classes[i] == 1 and scores[i] > threshold:\n",
    "                box = boxes[i]\n",
    "                cv2.rectangle(img,(box[1],box[0]),(box[3],box[2]),(255,0,0),2)\n",
    "                count+=1\n",
    "        cv2.putText(img,'Count = '+str(count),(10,400),cv2.FONT_HERSHEY_SIMPLEX, 1.25,(255,255,0),2,cv2.LINE_AA)\n",
    "        cv2.imwrite(\"./results/result%04i.jpg\" %no, img)\n",
    "        no+=1\n",
    "print(\"\\n\\t\\t\\tSuccessfully saved all results!\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
